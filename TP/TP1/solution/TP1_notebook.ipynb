{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# TP1\n\n## Dimitris Proios\n\n\n\n## Requirements install ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 1 -- Noise and Metrics\n\n### 1.a) Write a function that determines the Mean Squared Error (MSE) between two images x and y.\n\nIn MSE, the lower the error, the more \"similar\" the two images are\nThe two images must have the same dimension.\n\n- MSE definition \n\n$ MSE \u003d \\frac{1}{N M} \\sum{ _{i\u003d1} ^{N}  \\sum{ _{i\u003d1} ^{M} (x[i,j] - y[i,j]) ^2}}$ \n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\ndef mse(imageA, imageB) -\u003e float:\n\terr \u003d np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n\terr /\u003d float(imageA.shape[0] * imageA.shape[1])\t\n\treturn err\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Load 2 images to test functionality",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from PIL import Image\nimA \u003d Image.open(\u0027./data/hdr_images/img01.tif\u0027)\nimA",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\ndef readTifGrayScale(path):\n    img \u003d cv2.imread(path, -1)\n    return img\n\n\ndef showTifGrayScale(img, title \u003d \"\"):\n    plt.imshow(img, cmap \u003d \u0027gray\u0027, interpolation \u003d \u0027bicubic\u0027)\n    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    plt.title(title)\n    plt.show()\n    ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "img1 \u003d readTifGrayScale(\u0027./data/hdr_images/img01.tif\u0027)\nimg2 \u003d readTifGrayScale(\u0027./data/hdr_images/img02.tif\u0027)\nshowTifGrayScale(img1)\nshowTifGrayScale(img2)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 1.b)  Read in a new copy of the image cameraman.tif, keep it in its original datatype and range, i.e. uint8 and {0..255}.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "imgCam \u003d readTifGrayScale(\u0027./data/cameraman.tif\u0027)\nimgCam\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 1.c)  Now read in a second copy of the image cameraman.tif but map it to double and {0..1}. See Matlab im2double. Compare the two images using the MSE. Can you explain the result?\n\nThe mse is 17842.766630867263\nwhich I believe is correct since the mse is not immune to different range.\n### Notes \n- For numpy reference of types I used this documentation https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html\n- For the replaccement of im2doublle function I used https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html \n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "imgCam_double \u003d np.array(imgCam).astype(np.float32)\nimgCam_double \u003d np.interp(\n    imgCam_double, \n    (imgCam_double.min(), imgCam_double.max()), \n    (0, 1)\n)\nimgCam_double ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "imgCam_double.dtype ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "mse(imgCam_double, imgCam )\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 2 \n### 2.a) Refractor the PNSR definition such that the PSNR is expressed as a function of the noise variance $σ_z ^2 $. You may assume that $σ_z ^2  \u003d MSE(x, y)$ \n\n- PSNR original definition \n\u003cbr\u003e \n\n(1) $ PSNR \u003d 10 \\log_{10} \\frac{a^2}{MSE(x,y)} $ \n\u003cbr\u003e\n\n(2) $MSE(x,y) \u003d \\sigma _{z} ^2 $\n\u003cbr\u003e\n\n(1) (2) $ PSNR \u003d 10 \\log_{10} \\frac{a^2}{\\sigma _{z} ^2} $ \n\u003cbr\u003e \n\n $ PSNR \u003d 20 \\log_{10} a - 10\\log_{10}{\\sigma _{z} ^2}  $ \n\u003cbr\u003e \n\n $ PSNR - 20 \\log_{10} a  \u003d 10\\log_{10}{\\sigma _{z} ^2}  $ \n\u003cbr\u003e \n\n $ \\frac{PSNR - 20 \\log_{10} a }{10} \u003d \\log_{10}{\\sigma _{z} ^2}  $ \n\u003cbr\u003e \n\n (3) $ 10^ {\\frac{PSNR - 20 \\log_{10} a }{10}} \u003d \\sigma _{z} ^2  $ \n\nThis relationship above is used in 2.b.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 2.b) Add Gaussian noise to an image such that the PSNR ratio with the original image is 10dB, 20dB, 30dB and 40dB. Use randn, not imnoise.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import math \nPSNRs \u003d [10, 20, 30, 40]\ngetVarianceForPSNR \u003d lambda db: 10**((db-20 * math.log(255, 10))/10)\nvarianceList \u003d [(db, getVarianceForPSNR(db)) for db in PSNRs ]\nvarianceList\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "- Noise function:\n$Z_i\u003d N(\\mu, \\sigma ^2 )$\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def gaussianNoise(image, var, mean \u003d 0):\n      row,col \u003d image.shape\n      sigma \u003d var**0.5\n      randomGaus \u003d np.random.normal(mean,sigma,(row,col))\n      gaussNoiseMatrix \u003d randomGaus.reshape(row,col)\n      noisy \u003d image + gaussNoiseMatrix\n      return noisy, gaussNoiseMatrix\n\nimgCam \u003d readTifGrayScale(\u0027./data/cameraman.tif\u0027)\nimgCam_double \u003d np.array(imgCam).astype(\"float32\")\nimgCam_double \u003d np.interp(\n    imgCam_double, \n    (imgCam_double.min(), imgCam_double.max()), \n    (0, 1)\n)\n\nprint(\"original image\")\nshowTifGrayScale(imgCam, \"original\")\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 2.c) Show the noisy images on the screen. How do they look?\n\nThey look bad the more db we have \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def experiment(db, variance, img):\n    print(\"DB: \",db)\n    print(\"variance: \", variance)\n    noisedImgArray, gaussNoiseMatrix \u003d gaussianNoise(img, variance)\n    showTifGrayScale(noisedImgArray, \"gaussian noise :\" + str(db))\n    return noisedImgArray\n    \nnoised_images \u003d [(db, experiment(db,var, imgCam_double )) for db,var in iter(varianceList)]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### 2.d) Show the histograms for these noisy images, can you explain what you see?\nThe more noisy the image the higher the difference wiht the original graph.\nWe see the count for every pixel value of the image.\nOriginal image: \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def convertBack(im):\n    imconv\u003d np.interp(\n        im, \n        (im.min(), im.max()), \n        (0, 255)\n    )\n    imconv \u003d imconv.astype(\"uint8\")\n    return imconv\n\ndef hist(img):\n    imconv \u003d convertBack(img)\n    hist , bins \u003d np.histogram(imconv.ravel(),256,[0,256])\n    plt.hist(hist, bins\u003d bins)\n    plt.show()\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "hist(imgCam_double)\nfrom matplotlib import pyplot as plt\n[ hist(im) for db, im in iter(noised_images)]\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 2.e.1) Add salt \u0026 pepper Noise to an image until the PSNR ratio between the original and the noisy image is 40 dB. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import copy \ndef psnr(mseres):\n    PIXEL_MAX_SQUARE \u003d 1\n    mse_square \u003d math.sqrt(mseres )\n    part1 \u003d  math.log10(PIXEL_MAX_SQUARE / mse_square)\n    return 20 * part1\n\nimgCam \u003d readTifGrayScale(\u0027./data/cameraman.tif\u0027)\nimgCam_double \u003d np.array(imgCam).astype(\"float32\")\nimgCam_double \u003d np.interp(\n    imgCam_double, \n    (imgCam_double.min(), imgCam_double.max()), \n    (0, 1)\n)\n\ndef get_img_with_pepper_salt_noise(img, p, q):\n    im \u003d copy.deepcopy(img)\n    randnums \u003d np.random.rand(256,256)\n    im[np.logical_and(randnums \u003e p, randnums \u003c q)] \u003d 1\n    im[ randnums \u003c\u003d p] \u003d 0\n    return im \n\npepperedImg \u003d get_img_with_pepper_salt_noise(imgCam_double, p\u003d0.00015, q\u003d0.0003)\nmseNum  \u003d mse(imgCam_double,pepperedImg)\nprint(\"mse: \", mseNum)\nprint(\"psnr: \", psnr(mseNum))\nshowTifGrayScale(noised_images[3][1], \"gaussian image\")\nshowTifGrayScale(pepperedImg, \"Peppered image\")\nshowTifGrayScale(imgCam_double, \"Original image\")\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 2.e.2) Visually compare it to the 40dB noisy image to which Gaussian noise was added. What can you conclude?\nWith salt and pepper noise function the picture is barely modified at 40db.\nWhile with gaussia noise it is geavily modified.\n\nTo validate that the salt and pper nois is coorectly implemented I will try to augmenta the noise heavily.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "pepperedImg \u003d get_img_with_pepper_salt_noise(imgCam_double, p\u003d0.15, q\u003d0.3)\nmseNum  \u003d mse(imgCam_double,pepperedImg)\nprint(\"mse: \", mseNum)\nprint(\"psnr: \", psnr(mseNum))\nshowTifGrayScale(pepperedImg, \"Peppered image\")\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Low rank approximation via SVD\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Exercise 3. Read the image peppers.png and convert it to grayscale. Perform its low-rank approximation for k \u003d 1, ..., n. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimagePepperMatrix \u003d mpimg.imread(\"./data/peppers.png\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "plt.imshow(imagePepperMatrix)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "imagePepperMatrix.shape",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nU, S, VT \u003d np.linalg.svd(imagePepperMatrix)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# Keep k left\nU.shape",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# keep\nS.shape",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "VT.shape",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "U[0][0][0]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\ndef compress_svd(image,k):\n    \"\"\"\n    Perform svd decomposition and truncated (using k singular values/vectors) reconstruction\n    returns\n    --------\n      reconstructed matrix reconst_matrix, array of singular values s\n    \"\"\"\n    U,s,V \u003d np.linalg.svd(image,full_matrices\u003dFalse)\n    reconst_matrix \u003d np.dot(U[:,:k],np.dot(np.diag(s[:k]),V[:k,:]))\n   \n    return reconst_matrix,s\n\n\ndef compress_show_color_images_layer(image, k):\n    \"\"\"\n     compress and display the reconstructed color image using the layer method \n    \"\"\"\n    original_shape \u003d image.shape\n    image_reconst_layers \u003d [compress_svd(image[:,:,i],k)[0] for i in range(3)]\n    image_reconst \u003d np.zeros(image.shape)\n    for i in range(3):\n        image_reconst[:,:,i] \u003d image_reconst_layers[i]\n    return image_reconst\n\nfig\u003dplt.figure(figsize\u003d(8, 8))\ncolumns \u003d 4\nrows \u003d 5\nk\u003d1\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    img \u003d compress_show_color_images_layer(imagePepperMatrix,k)\n    plt.imshow(img)\n    k+\u003d 1\n\nplt.show()\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Plot the dependence between the k and MSE of k-rank approximation version of original image. Make a conclusion.\n\n### Conclusion:\nAs we see in the experiment below each K component adds more of the \"information\" on the image.\nThis is consistent with the theory since the compoents include variance of the information.\nThis relationship is not linear since the first components are sorted to hold more of the variance observed in our data.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "mses \u003d [\n    (\n        k,\n        mse(\n            imagePepperMatrix,\n            compress_show_color_images_layer(imagePepperMatrix,k)\n        )\n    )\n    for k in range(1,384)\n]\nplt.plot(\n    [i[0] for i in mses],\n    [i[1] for i in mses]\n)\nplt.ylabel(\u0027k\u0027)\nplt.xlabel(\u0027mse\u0027)\nplt.show()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n### Exercise 4. \n#### 4.1)Read the image peppers.png and convert it to grayscale and add Gaussian noise N (0, 625). Perform its low-rank approximation for k \u003d 1, ..., n. ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2 \nimport numpy as np\nimagePepperMatrix \u003d mpimg.imread(\"./data/peppers.png\")\ngray__imagePepperMatrix \u003d cv2.cvtColor(\n    imagePepperMatrix, \n    # cv2.COLOR_BGR2GRAY\n    cv2.COLOR_RGB2GRAY\n)\nfig\u003dplt.figure(figsize\u003d(10, 10))\nfig.add_subplot(1, 2, 1)\nplt.title( \"grayscale \")\nplt.imshow(gray__imagePepperMatrix,  cmap\u003d\u0027gray\u0027 )\nnoised__gray__imagePepperMatrix, noiseMatrix\u003d  gaussianNoise(gray__imagePepperMatrix, 625, 0)\nfig.add_subplot(1, 2, 2)\nplt.title( \"grayscale noised \")\nplt.imshow(noised__gray__imagePepperMatrix,  cmap\u003d\u0027gray\u0027 )\nplt.show()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### 4.2 Plot the dependence between the k and MSE of k-rank approximation version of original image. Make a conclusion.\nThe Plot the dependence between\nthe k and MSE of k-rank approximation version of original image. (mistake?)\nI am plotting the approximation with grayscale noised image.\n\n#### Conclusion \nThe svd reconstruction ratio is maintained even with the noised image. ",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def grayscale_compress_svd(image,k):\n    \"\"\"\n    Perform svd decomposition and truncated (using k singular values/vectors) reconstruction\n    returns\n    --------\n      reconstructed matrix reconst_matrix, array of singular values s\n    \"\"\"\n    U,s,V \u003d np.linalg.svd(image,full_matrices\u003dFalse)\n    reconst_matrix \u003d np.dot(U[:,:k],np.dot(np.diag(s[:k]),V[:k,:]))   \n    return reconst_matrix,s\n\n\ndef grayscale_compress_show_color_images_layer(image, k):\n    \"\"\"\n     compress and display the reconstructed color image using the layer method \n    \"\"\"\n    original_shape \u003d image.shape\n    image_reconst_layers \u003d grayscale_compress_svd(image ,k)\n    image_reconst \u003d image_reconst_layers\n    return image_reconst[0]\n\nmses \u003d [\n    (\n        k,\n        mse(\n            gray__imagePepperMatrix,\n            grayscale_compress_show_color_images_layer(gray__imagePepperMatrix,k)\n        )\n    )\n    for k in range(1,384)\n]\nplt.plot(\n    [i[0] for i in mses],\n    [i[1] for i in mses]\n)\nplt.ylabel(\u0027k\u0027)\nplt.xlabel(\u0027mse\u0027)\nplt.show()\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Noise Visibility Function (NVF)\n${NVF \u003d \\frac{1}{1 + \\theta \\sigma _{x} ^{2} (i, j)}}$\n\u003cbr\u003e\n${\\theta \u003d \\frac{D}{ \\sigma _{x_{max}} ^{2} }}$\n\n### Exercise 5. ex\n(a) Read the image lena.png and convert it to grayscale.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2 \nimport numpy as np\nimageLena \u003d mpimg.imread(\"./data/lena.png\")\ngray__imageLena \u003d cv2.cvtColor(\n    imageLena, \n    cv2.COLOR_RGB2GRAY\n    \n)\nplt.imshow(gray__imageLena,  cmap\u003d\u0027gray\u0027 )\n(h, w) \u003d gray__imageLena.shape[:2] \n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n\n(b) Add a watermark to the image with and without applying NVF function the different\nvalues of ${σ ^z _2}$ (10, 25, 50, 75) and D. \n\u003cbr\u003e\nChoose the window size appropriate to used image.\n\n\u003cbr\u003e\n\nWhat can you say about the impact of NVF function?\n\n#### Solution \nI am confused if the watermarking means to put an image on top of the other with transparency,  or to hide data in the other image.\nTODO https://www.pyimagesearch.com/2016/04/25/watermarking-images-with-opencv-and-python/\n\nFistly after defining the noise visibillity function, \nI create a grayscale watermark image.\nThen I add a another dimension for the alpha transparency parameter.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def theta(D, maxLocalVar):\n    return \n\ndef NVF(i, j, theta, variance_matrix):\n    return 1/(1+ theta* variance_matrix[i][j])\n\ndef embeddingEquation(i,j, NVF, x, z):\n    return x[i][j] + (1-NVF) * z[i][j]\n\nwatermark \u003d cv2.imread(\"./data/watermark.png\", cv2.IMREAD_UNCHANGED)\ngray__watermark  \u003d cv2.cvtColor(\n    watermark, \n    cv2.COLOR_RGB2GRAY\n)\n(wH, wW) \u003d gray__watermark.shape[:2]\ngray__watermark \u003d gray__watermark.astype(\"float32\")\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "arr \u003d np.ones((wH, wW)) * 255\ngray_tansp \u003d np.dstack([gray__watermark, arr ])\ngray_tansp",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "output \u003d gray__imageLena.copy()\nh, w \u003d output.shape[:2]\nplt.imshow(gray__watermark,  cmap\u003d\u0027gray\u0027)\noverlay \u003d np.zeros((h, w), dtype\u003d\"uint8\")\noverlay[h - wH:h, w - wW:w] \u003d gray__watermark\noverlay \u003d overlay.astype(\"float32\")\n# overlay, output\nplt.imshow(overlay,  cmap\u003d\u0027gray\u0027)\nplt.show()\nplt.imshow(output,  cmap\u003d\u0027gray\u0027)\nplt.show()\nprint(output) \n# cv2.addWeighted(overlay, 0.25, output, 1.0, 0, output)\nprint(output) \nplt.imshow(output,  cmap\u003d\u0027gray\u0027)\nplt.show()\n# gray__watermark.shape, output.shape\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "(c) Report the dependency between the parameters ${σ ^z _2}$ , D and original image.\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\nExercise 6. ex\n(a) You are given a set of images hdr images. Combine the images (not necessary all) to one\nimage in such a way that the result image has higher quality then all given images in the\nset. You can sum, subtract the images, divide by some constant, multiply by some mask,\netc.\n\n(b) Visualise the results and explain how did you obtain them.\n\nSolution for a, b\nBase on this example:\nTODO https://docs.opencv.org/4.1.0/d2/df0/tutorial_py_hdr.html",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport cv2 \nimport matplotlib.pyplot as plt\n\nimg_fn\u003d [\"./data/hdr_images/\"+f for f in [\"img01.tif\", \"img02.tif\", \"img03.tif\", \"img04.tif\", \"img05.tif\"]]\nimg_list \u003d [cv2.imread(fn, -1) for fn in img_fn]\nexposure_times \u003d np.array([0.0333, 0.25, 1.0, 2.5, 15.0], dtype\u003dnp.float32)\n\n#Merge exposures into HDR image\nmerge_debevec \u003d cv2.createMergeDebevec()\nhdr_debevec \u003d merge_debevec.process(img_list, times\u003dexposure_times.copy())\nmerge_robertson \u003d cv2.createMergeRobertson()\nhdr_robertson \u003d merge_robertson.process(img_list, times\u003dexposure_times.copy())\n\n# Tonemap HDR image\ntonemap1 \u003d cv2.createTonemap(gamma\u003d2.2)\nres_debevec \u003d tonemap1.process(hdr_debevec.copy())\n\n# Exposure fusion using Mertens\nmerge_mertens \u003d cv2.createMergeMertens()\nres_mertens \u003d merge_mertens.process(img_list)\n# Convert datatype to 8-bit and save\nres_debevec_8bit \u003d np.clip(res_debevec*255, 0, 255).astype(\u0027uint8\u0027)\n# res_robertson_8bit \u003d np.clip(res_robertson*255, 0, 255).astype(\u0027uint8\u0027)\nres_mertens_8bit \u003d np.clip(res_mertens*255, 0, 255).astype(\u0027uint8\u0027)\ncv2.imwrite(\"ldr_debevec.jpg\", res_debevec_8bit)\ncv2.waitKey(0)\ncv2.destroyAllWindows() #close the image window\nimg1\u003d cv2.imread(\"ldr_debevec.jpg\")\nrgb \u003d cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\nplt.imshow(rgb, cmap \u003d plt.cm.Spectral)\nplt.show()\ncv2.imwrite(\"fusion_mertens.jpg\", res_mertens_8bit)\ncv2.waitKey(0)\ncv2.destroyAllWindows() #close the image window\nimg2\u003d cv2.imread(\"fusion_mertens.jpg\")\nrgb \u003d cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\nplt.imshow(rgb, cmap \u003d plt.cm.Spectral)\nplt.show()\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "RENOIR\n### You are given a ”renoir” set of two images (reference and noisy) from the RENOIR dataset 2 .\n### Exercise 7. ex\n(a) Visualise all color channels of both images. \nAre the all channels equally affected by the noise?\n\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import scipy.ndimage as ndimage\nfrom skimage.exposure import histogram\n\nim1 \u003d ndimage.imread(\"./data/renoir/Noisy.bmp\")\nim2 \u003d ndimage.imread(\"./data/renoir/Reference.bmp\", -1)\n\nplt.imshow(im1)\nplt.show()\nplt.imshow(im2)\nplt.show()\n\nred_images \u003d im1[:,:,0]\ngreen_images \u003d im1[:,:,1]\nblue_images \u003d im1[:,:,2]",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\nhistogram(red_images)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\nplt.plot(\n    np.ndarray.flatten(green_images)\n)\nplt.show()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "plt.plot(\n    np.ndarray.flatten(blue_images)\n)\nplt.show()\n    \nplt.ylabel(\u0027pixel \u0027)\nplt.xlabel(\u0027value \u0027)\nplt.show()\nplt.plot(\n    np.ndarray.flatten(im2)\n)\nplt.show()\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "(b) Try to decrease the noise via image down/up sampling.\n\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "(a) Do it for the RGB image. Measure the PSNR between the reference and de-noised\nimages 3 .\n\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "(b) Do it for the grayscale image. Measure the PSNR between the grayscale reference\nand de-noised images.\n\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "(c) Do the denoising for the RGB image and after convert it to the grayscale. Measure\nthe PSNR. Does the obtained result is different from the (b)? Explain the r\n\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\nExercise 8. You are given a set of 4 images: tp1 101.png - tp1 104.png. For one of these\nimages perform the segmentation of the text information. See the example in Figure 3. Some\ngraphical elements can be segmented as well.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "#TODO https://scikit-image.org/docs/dev/auto_examples/edges/plot_edge_filter.html\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage.filters import gaussian, frangi\nimage \u003d cv2.imread(\"./data/tp1_101.png\")\nimage.shape\nedge_gaussian \u003d gaussian(image)\nedge_frangi \u003d frangi(image)\nfig, ax \u003d plt.subplots(ncols\u003d3, sharex\u003dTrue, sharey\u003dTrue,\n                       figsize\u003d(8, 4))\nax[0].imshow(image)\nax[0].set_title(\u0027original image \u0027)\nax[1].imshow(edge_gaussian)\nax[1].set_title(\u0027Gaussian Edge Detection\u0027)\nax[2].imshow(edge_frangi)\nax[2].set_title(\u0027frangi Edge Detection\u0027)\n\n\nfor a in ax:\n    a.axis(\u0027off\u0027)\n\nplt.tight_layout()\nplt.show()\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Nuts and bolts\nIn this little project you will design and test a program that can recognize various nuts and\nbolts in an image using Matlab’s morphological functions and a bit of statistics. The image can\nbe seen in Figure 4. Matlab contains an excellent tutorial segmenting and counting rice in an\nimage, which you can work through as preparation.\nThe principle steps that need to be done are the following:\n• Segment the foreground which contains all parts, from the background. You can use\n4\nhttp://www.mathworks.ch/ch/help/images/image-enhancement-and-analysis.html\nmorphological opening, e.g. imopen to ascertain background statistics or use the so called\nOtsi’s method implemented by Matlab graythresh.\n• Use morphology to remove any noise from the image\n• Select all individual items using Matlab’s bwlabel and bwconncomp.\n• To gather statistics deploy Matlab’s regionprops function. It is capable of collecting a\nvast amount of information on binary objects which in term can be used to distinguish\nthe various parts from each other.\n• Find a combination of metrics to separate the different parts as best as possible.\n\n### Exercise 9. ex\n1. Implement the image segmentation and statistics gathering functions\n2. Report on what statistics work and why (not).",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyCharm (advanced_image_processing)",
      "language": "python",
      "name": "pycharm-670c054d"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}