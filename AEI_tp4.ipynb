{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AEI_tp4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/partizanos/advanced_image_processing/blob/master/AEI_tp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mblg1yLAKLJE",
        "colab_type": "text"
      },
      "source": [
        "# Tp4 image processing JPEG -- DIMITRIS PROIOS\n",
        "\n",
        "## Exercise 1 (a) Implement by yourself the JPEG compression algorithm described above.\n",
        "### 1.Color space transformation :\n",
        "#### RGB color space to YCbCr color space conversion:\n",
        "\n",
        "\n",
        "\n",
        "First, the image should be converted from RGB into a different color space called Y′CBCR (or, informally, YCbCr). \n",
        "\n",
        "It has three components: \n",
        "- the Y' component represents the brightness of a pixel, \n",
        "- CB and CR components represent the chrominance (split into blue and red components). \n",
        "\n",
        "The Y′CBCR color space conversion allows greater compression without a significant effect on perceptual image quality (or greater perceptual image quality for the same compression)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdT1tAIe-k2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def extract_colors(img):\n",
        "  R_DIMENSION = img[:, :, 0]\n",
        "  G_DIMENSION = img[:, :, 1]\n",
        "  B_DIMENSION = img[:, :, 2]\n",
        "  return R_DIMENSION, G_DIMENSION, B_DIMENSION\n",
        "\n",
        "\n",
        "\n",
        "# original implementation of descrition\n",
        "\n",
        "def YCbCr(R_DIMENSION,G_DIMENSION,B_DIMENSION): \n",
        "  \n",
        "  Y = np.add(np.add(0.299 * R_DIMENSION, 0.587 * G_DIMENSION), 0.114 * B_DIMENSION)\n",
        "  \n",
        "  Cb = - 0.1687 * R_DIMENSION - 0.3313 * G_DIMENSION + 0.5 * B_DIMENSION + 128\n",
        "  \n",
        "  Cr = 0.5 * R_DIMENSION - 0.4187 * G_DIMENSION - 0.0813 * B_DIMENSION + 128\n",
        "  \n",
        "  R_DIMENSION = Y + 1.402 * (Cr - 128)\n",
        "  \n",
        "  G_DIMENSION = Y - 0.34414 * (Cb - 128) - 0.71414 * (Cr - 128)\n",
        "  \n",
        "  B_DIMENSION = Y + 1.772 * (Cb - 128)\n",
        "  \n",
        "  return Y, Cb, Cr, R_DIMENSION, G_DIMENSION, B_DIMENSION\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um3OPGc4pFzs",
        "colab_type": "text"
      },
      "source": [
        "### 2.  Downsampling \n",
        "\n",
        "#### Keep the Y component. and downsample the Cb and Cr components in 2 times.\n",
        "\n",
        "\n",
        "- Due to color and brightness densities, humans can see considerably more fine detail in the brightness of an image (the Y' component)  than in the hue and color saturation of an image (the Cb and Cr components). Using this knowledge, encoders can be designed to compress images more efficiently.\n",
        "\n",
        "\n",
        "- The transformation into the Y′CBCR color model enables reduce the spatial resolution of the Cb and Cr components (called \"downsampling\" or \"chroma subsampling\"). The ratios at which the downsampling is ordinarily done for JPEG images are: \n",
        "  - 4:4:4 (no downsampling)\n",
        "  - 4:2:2 (reduction by a factor of 2 in the horizontal direction), \n",
        "  - (most commonly) 4:2:0 (reduction by a factor of 2 in both the horizontal and vertical directions). \n",
        "\n",
        "For the rest of the compression process, Y', Cb and Cr are processed separately and in a very similar manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCRTdeCd5jZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO try different downsample method https://stackoverflow.com/questions/13242382/resampling-a-numpy-array-representing-an-image\n",
        "# verify matlab downsampl\n",
        "\n",
        "def downsampleChannels(Cb, Cr, dimensions_number=2):\n",
        "  def downsample_image(img, skip):\n",
        "      return img[::skip,::skip]\n",
        "  \n",
        "  # imresize \n",
        "  d_cb  = downsample_image(Cb, 2)\n",
        "  #   d_cb  = downsample_image(d_cb, 2)\n",
        "  d_cr  = downsample_image(Cr, 2)\n",
        "  #   d_cr  = downsample_image(d_cr, 2)\n",
        "  return d_cb, d_cr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blEx-UAr7xch",
        "colab_type": "code",
        "outputId": "0c63cdd8-2142-4690-ae06-664189d02c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import math\n",
        "from scipy import fftpack \n",
        "\n",
        "\n",
        "def main():\n",
        "  response = requests.get(\"https://raw.githubusercontent.com/partizanos/advanced_image_processing/master/TP/TP4/test.png\")\n",
        "  im = Image.open(BytesIO(response.content))\n",
        "  img = np.array(im)\n",
        "  M, N, _ = img.shape\n",
        "  max_M = int(math.modf(M/8)[1] *8)\n",
        "  max_N = int(math.modf(N/8)[1] *8)\n",
        "  crop = lambda img:img[:max_M, :max_N, :]\n",
        "  img = crop(img )\n",
        "  return img, M, N,max_M, max_N\n",
        "\n",
        "\n",
        "\n",
        "def test(showImg=False):\n",
        "  img, M, N,max_M, max_N = main()\n",
        "  if(showImg):\n",
        "    plt.imshow(img, cmap=plt.cm.Spectral)\n",
        "    plt.title(\"Orignal\")\n",
        "  \n",
        "  \n",
        "  R, G, B = extract_colors(img)\n",
        "  \n",
        "  \n",
        "  assert R.shape == (864, 1296)\n",
        "  assert G.shape == (864, 1296)\n",
        "  assert B.shape == (864, 1296)\n",
        "  \n",
        "  Y, Cb, Cr, R, G, B  = YCbCr(R, G, B )\n",
        "  \n",
        "  assert R.shape == (864, 1296)\n",
        "  assert G.shape == (864, 1296)\n",
        "  assert B.shape == (864, 1296)\n",
        "  assert Y.shape == (864, 1296)\n",
        "  assert Cr.shape == (864, 1296)\n",
        "  assert Cb.shape == (864, 1296)\n",
        "  \n",
        "  \n",
        "  d_cb, d_cr = downsampleChannels(Cb, Cr)\n",
        "  assert Y.shape == (864, 1296)\n",
        "  assert d_cb.shape == (432, 648)\n",
        "\n",
        "  return(\n",
        "      img, M, N,max_M, max_N , R, G, B , Y, Cb, Cr, d_cb, d_cr \n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "img, M, N,max_M, max_N , R, G, B , Y, Cb, Cr, d_cb, d_cr  = test()\n",
        "print(\"test succeed\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test succeed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMdY0ECqpguK",
        "colab_type": "text"
      },
      "source": [
        "### 3. Preprocessing for DCT transformation\n",
        "\n",
        "#### 3.1 Split the image into 8 × 8 non-overlapping blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgfX-mW92E-S",
        "colab_type": "code",
        "outputId": "e00eec1f-7236-4bb1-e8d4-790c66d135f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def img_2_block(Y, cb, cr, number_octads):\n",
        "  number_octads = int(max_M* max_N / 64)\n",
        "  Y_r = Y.reshape((number_octads, 8,8))\n",
        "  Cb_r = Cb.reshape((number_octads, 8,8))\n",
        "  Cr_r = Cr.reshape((number_octads, 8,8))\n",
        "  return Y_r, Cb_r,Cr_r\n",
        "  \n",
        "# test TODO grayscale image \n",
        "#test\n",
        "#   Y_r[0] = [\n",
        "#       [52, 55, 61, 66, 70, 61, 64, 73],\n",
        "#       [63, 59, 66, 90, 109, 85, 69, 72],\n",
        "#       [62, 59, 68, 113, 144, 104, 66, 73],\n",
        "#       [63, 58, 71, 122, 154, 106, 70, 69],\n",
        "#       [67, 61, 68, 104, 126, 88, 68, 70],\n",
        "#       [79, 65, 60, 70, 77, 63, 58, 75],\n",
        "#       [85, 71, 64, 59, 55, 61, 65, 83],\n",
        "#       [87, 79, 69, 68, 65, 76, 78, 94]\n",
        "#   ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Y_r, Cb_r, Cr_r = img_2_block(Y, d_cb, d_cr, (max_M, max_N ) )\n",
        "\n",
        "# TODO test\n",
        "Y_r.shape, Cb_r.shape, Cr_r.shape\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17496, 8, 8), (17496, 8, 8), (17496, 8, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6voyI0oIpk7b",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2 In each block subtract global mean computed as 2 k−1 , where k is the number of gray levels in the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr5VEMiyFGSd",
        "colab_type": "code",
        "outputId": "b65732e4-eed6-45b0-c680-5797667a910e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "def global_mean(img):\n",
        "  global_mean = 128\n",
        "  img=img - global_mean\n",
        "  img = img.astype(\"int\")\n",
        "  return img\n",
        "\n",
        "Y_r = global_mean(Y_r)\n",
        "Cb_r = global_mean(Cb_r)\n",
        "Cr_r = global_mean(Cr_r)\n",
        "Y_r.shape, Y_r[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17496, 8, 8), array([[-110, -108, -101, -114, -115, -112, -114, -117],\n",
              "        [-116, -114, -113, -107, -105, -104,  -98,  -94],\n",
              "        [ -86,  -90,  -98, -105, -110,  -99, -103, -106],\n",
              "        [-110, -109, -102, -101,  -91,  -73,  -73,  -63],\n",
              "        [ -35,  -27,  -77, -102,  -90,  -67,  -64,  -70],\n",
              "        [ -66,  -94,  -97,  -95,  -97,  -94,  -86,  -41],\n",
              "        [  13,   26,   30,   14,  -10,  -22,   22,   31],\n",
              "        [  40,   33,    0,  -38,  -44,   11,    5,  -28]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bdpCAJpMrJp",
        "colab_type": "text"
      },
      "source": [
        "### Step 4. DCT transformation per block: T (u, v)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGn7u4fgxn7f",
        "colab_type": "code",
        "outputId": "010a3b8c-69a5-470a-c840-631a79da8cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "# TODO aply and inverse image should be same MSE =10** -10\n",
        "def dct_2d(image):\n",
        "  return fftpack.dct(fftpack.dct(image.T, norm='ortho').T, norm='ortho')\n",
        "\n",
        "  \n",
        "def ict_2d(): \n",
        "  return fftpack.dct(fftpack.dct(image.T, norm='ortho').T, norm='ortho')\n",
        "\n",
        "Y_dct = dct_2d(Y_r)\n",
        "Cb_dct = dct_2d(Cb_r)\n",
        "Cr_dct = dct_2d(Cr_r)\n",
        "Y_dct[0]\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.32424058e+04,  1.48205303e+01,  1.61819283e+01,\n",
              "        -1.56592549e+01, -2.44144322e+01, -6.41182556e+00,\n",
              "        -1.04407181e+01, -2.21986564e+00],\n",
              "       [-2.31538227e+04, -4.99256123e+01, -2.61065820e+01,\n",
              "         6.83830692e+00,  5.28970455e+00, -1.46695910e+01,\n",
              "         5.76516143e+00,  6.54256376e+00],\n",
              "       [-2.32621961e+04,  1.75776026e+00,  5.30119326e+00,\n",
              "        -8.99781826e+00, -3.43202660e+00,  5.68003455e-01,\n",
              "        -3.02905205e+00,  1.42639779e+00],\n",
              "       [-2.31532560e+04, -1.55695129e+01, -3.25400242e+01,\n",
              "        -4.37613444e-01, -3.07652852e+00, -4.12470487e+00,\n",
              "        -8.42548523e+00, -9.65467050e-01],\n",
              "       [-2.32600551e+04, -1.88533151e+01,  1.49542199e+01,\n",
              "         3.14233930e+00,  2.84665758e+00, -6.67631632e-01,\n",
              "        -5.32340389e+00,  7.48799404e-01],\n",
              "       [-2.31335406e+04, -2.72705147e+00, -2.90658725e+01,\n",
              "        -4.60730132e+00, -1.04243799e-01, -1.35655872e+00,\n",
              "         7.30172826e-01,  2.95232948e+00],\n",
              "       [-2.32723585e+04,  1.49727949e+00,  2.62745663e+01,\n",
              "        -1.03652833e+01, -1.84110586e+01, -4.72244520e-01,\n",
              "        -9.69709207e+00, -5.36950476e+00],\n",
              "       [-2.31363391e+04, -3.08765194e+01, -1.05509200e+01,\n",
              "         2.06557955e+00, -4.66691468e+00, -6.56946256e+00,\n",
              "        -4.78357823e+00, -3.16868507e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oPJIdwFKj3y",
        "colab_type": "text"
      },
      "source": [
        "### Step 5. Block coefficients quantization:\n",
        "\n",
        "$T(u,v) = round \\frac{T(u,v)} {Z(u,v)}  $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFs8JiFIsjIr",
        "colab_type": "code",
        "outputId": "28064fb7-31e3-4679-f537-9591175092df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "def quantization(Y_dct, Cb_dct, Cr_dct, Z):\n",
        "  T_Y = np.round(Y_dct/Z)\n",
        "  T_cb = np.round(Cb_dct/Z)\n",
        "  T_cr = np.round(Cr_dct/Z)\n",
        "  \n",
        "  return (T_Y, T_cb, T_cb)\n",
        " \n",
        "  \n",
        "######################\n",
        "\n",
        "\n",
        "Z = [\n",
        "      [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "      [12, 12, 14, 19, 26, 28, 60, 55],\n",
        "      [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "      [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "      [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "      [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "      [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "      [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "]\n",
        "\n",
        "(T_Y, T_cb, T_cr) = quantization(Y_dct, Cb_dct, Cr_dct, Z)\n",
        "T_cr.shape, T_cr[0, :]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17496, 8, 8),\n",
              " array([[-176.,   -0.,    0.,   -0.,    0.,   -0.,   -0.,   -0.],\n",
              "        [-234.,    1.,    0.,   -0.,   -0.,   -0.,   -0.,   -0.],\n",
              "        [-201.,   -0.,   -0.,   -0.,   -0.,   -0.,    0.,    0.],\n",
              "        [-201.,    0.,    0.,   -0.,    0.,   -0.,    0.,    0.],\n",
              "        [-156.,   -0.,   -0.,    0.,    0.,   -0.,    0.,    0.],\n",
              "        [-117.,    0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.],\n",
              "        [ -58.,   -0.,   -0.,    0.,   -0.,   -0.,   -0.,   -0.],\n",
              "        [ -39.,    0.,    0.,   -0.,   -0.,    0.,   -0.,    0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-cJ7BaUK3N3",
        "colab_type": "text"
      },
      "source": [
        "Step 6. Symbols encoding:\n",
        "6.1  Zig-zag scanning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bYt9Av9K7YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://rosettacode.org/wiki/Zig-zag_matrix#Python\n",
        "import operator\n",
        "\n",
        "def zigzag(n):\n",
        "    '''zigzag rows'''\n",
        "    def compare(xy):\n",
        "        x, y = xy\n",
        "        return (x + y, -y if (x + y) % 2 else y)\n",
        "      \n",
        "    xs = range(n)\n",
        "    \n",
        "    return {index: n for n, index in enumerate(sorted(\n",
        "        ((x, y) for x in xs for y in xs),\n",
        "        key=compare\n",
        "    ))}\n",
        "\n",
        "\n",
        "x = zigzag(8)\n",
        "zig_zag_indices = sorted(x.items(), key=operator.itemgetter(1))\n",
        "zig_zag_indices = [ i[0] for i in zig_zag_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEKcRA20rEw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# zig zag representation\n",
        "Y_zigzag = []\n",
        "cb_zigzag = []\n",
        "cr_zigzag = []\n",
        "for block in range(T_Y.shape[0]):\n",
        "  for i in zig_zag_indices:\n",
        "    Y_zigzag.append(T_Y[block][i])\n",
        "    cb_zigzag.append(T_cb[block][i])\n",
        "    cr_zigzag.append(T_cr[block][i])\n",
        "# Y_zigzag = [T_Y[block][i] for i in zig_zag_indices for block in range(T_Y.shape[0])]\n",
        "# Cb_zigzag =  [[T_cb[block][i]for i in zig_zag_indices] for block in range(T_cb.shape[0])]\n",
        "# Cr_zigzag =  [[T_cr[block][i]for i in zig_zag_indices] for block in range(T_cr.shape[0])]\n",
        "\n",
        "# TEST \n",
        "# Y_zigzag[:3], [T_Y[0][0,0],T_Y[0][0,1],T_Y[0][1,0]], T_Y[0]\n",
        "assert Y_zigzag[:3][0] == T_Y[0][0,0]\n",
        "assert Y_zigzag[:3][1] == T_Y[0][0,1]\n",
        "assert Y_zigzag[:3][2] == T_Y[0][1,0]\n",
        "Y_zigzag = np.asarray(Y_zigzag)\n",
        "cb_zigzag = np.asarray(cb_zigzag)\n",
        "cr_zigzag = np.asarray(cr_zigzag)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phU4ORtD7tx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge blocks\n",
        "Y_merged = Y_zigzag.reshape((max_M, max_N))\n",
        "Cb_merged = cb_zigzag.reshape((max_M, max_N))\n",
        "Cr_merged = cr_zigzag.reshape((max_M, max_N))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC5BxoP-qIYd",
        "colab_type": "text"
      },
      "source": [
        "6.2 Huffman coding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORWYa1r5n29-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count frequency of each color \n",
        "def count_color_freq(img):\n",
        "  unique, counts = np.unique(img, return_counts=True)\n",
        "  return dict(zip(unique, counts))\n",
        "\n",
        "frequencies = [count_color_freq(chanel) for chanel in [Y_merged, Cb_merged, Cr_merged] ] \n",
        "\n",
        "total_pixels = max_N *max_M\n",
        "assert max_N *max_M == sum(frequencies[0].values())\n",
        "\n",
        "# frequencies = [ { k:v/total_pixels for k,v in f.items()} for f in frequencies]\n",
        "probs = []\n",
        "for f_index in range(len(frequencies)):\n",
        "  probs.append({ k:v/total_pixels for k,v in frequencies[f_index].items()})\n",
        "# probs[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtbXPytcR2Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # !pip install dahuffman\n",
        "# from dahuffman import HuffmanCodec\n",
        "\n",
        "# codec = HuffmanCodec.from_frequencies({'e': 100, 'n':20, 'x':1, 'i': 40, 'q':3})\n",
        "# encoded = codec.encode('exeneeeexniqneieini')\n",
        "# codec.decode(encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk-31QpcMQ7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/mreid/fdf6353ec39d050e972b\n",
        "# Example Huffman coding implementation\n",
        "# Distributions are represented as dictionaries of { 'symbol': probability }\n",
        "# Codes are dictionaries too: { 'symbol': 'codeword' }\n",
        "\n",
        "def huffman(p):\n",
        "    '''Return a Huffman code for an ensemble with distribution p.'''\n",
        "    assert(sum(p.values()) > 0.99) # Ensure probabilities sum to 1\n",
        "    assert(sum(p.values()) < 1.01) # Ensure probabilities sum to 1\n",
        "\n",
        "    # Base case of only two symbols, assign 0 or 1 arbitrarily\n",
        "    if(len(p) == 2):\n",
        "        return dict(zip(p.keys(), ['0', '1']))\n",
        "\n",
        "    # Create a new distribution by merging lowest prob. pair\n",
        "    p_prime = p.copy()\n",
        "    a1, a2 = lowest_prob_pair(p)\n",
        "    p1, p2 = p_prime.pop(a1), p_prime.pop(a2)\n",
        "    p_prime[a1 + a2] = p1 + p2\n",
        "\n",
        "    # Recurse and construct code on new distribution\n",
        "    c = huffman(p_prime)\n",
        "    ca1a2 = c.pop(a1 + a2)\n",
        "    c[a1], c[a2] = ca1a2 + '0', ca1a2 + '1'\n",
        "\n",
        "    return c\n",
        "\n",
        "def lowest_prob_pair(p):\n",
        "    '''Return pair of symbols from distribution p with lowest probabilities.'''\n",
        "    assert(len(p) >= 2) # Ensure there are at least 2 symbols in the dist.\n",
        "\n",
        "    sorted_p = sorted(p.items())\n",
        "    return sorted_p[0][0], sorted_p[1][0]\n",
        "\n",
        "# Example execution\n",
        "# ex1 = { 'a': 0.5, 'b': 0.25, 'c': 0.25 }\n",
        "# huffman(ex1) # => {'a': '0', 'c': '10', 'b': '11'}\n",
        "# huffmans = [huffman(f) for f in range(len(frequencies))]\n",
        "\n",
        "\n",
        "\n",
        "huffman_trees = [ huffman(probs[i]) for i in range(3)]\n",
        "\n",
        "# probs[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOKRN70wWyQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "huffman_trees[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t19TCgecJGHZ",
        "colab_type": "text"
      },
      "source": [
        "b) Take a colour image test.png. Compress this image by your JPEG algorithm implemen-\n",
        "tation.\n",
        "\n",
        "(c) Perform the image reconstruction.\n",
        "\n",
        "(d) Display the original and reconstructed images. Compare those images based on the MSE.\n",
        "Make a conclusion about the compression efficiency based on the visual images quality\n",
        "and the files size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW3l5ELDV_a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def inverse_extract_colors(R, G, B):\n",
        "  img = np.zeros(M, N, 3)\n",
        "  img[:, :, 0] = R\n",
        "  img[:, :, 1] = G\n",
        "  B = img[:, :, 2] = B\n",
        "  return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xna8Ns9BWCIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def YCbCr( R_DIMENSION, G_DIMENSION, B_DIMENSION): \n",
        "  \n",
        "  Y = np.add(np.add(0.299 * R_DIMENSION, 0.587 * G_DIMENSION), 0.114 * B_DIMENSION)\n",
        "  \n",
        "  Cb = - 0.1687 * R_DIMENSION - 0.3313 * G_DIMENSION + 0.5 * B_DIMENSION + 128\n",
        "  \n",
        "  Cr = 0.5 * R_DIMENSION - 0.4187 * G_DIMENSION - 0.0813 * B_DIMENSION + 128\n",
        "  \n",
        "  R_DIMENSION = Y + 1.402 * (Cr - 128)\n",
        "  \n",
        "  G_DIMENSION = Y - 0.34414 * (Cb - 128) - 0.71414 * (Cr - 128)\n",
        "  \n",
        "  B_DIMENSION = Y + 1.772 * (Cb - 128)\n",
        "  \n",
        "  return Y, Cb, Cr, R_DIMENSION, G_DIMENSION, B_DIMENSION\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrLnjJJHewWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upsample\n",
        "# https://stackoverflow.com/questions/13242382/resampling-a-numpy-array-representing-an-image\n",
        "def upsample():\n",
        "  print 'Resampled by a factor of 2 with nearest interpolation:'\n",
        "  print scipy.ndimage.zoom(x, 2, order=0)\n",
        "\n",
        "\n",
        "  print 'Resampled by a factor of 2 with bilinear interpolation:'\n",
        "  print scipy.ndimage.zoom(x, 2, order=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxA6eOJKguz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# blck 2 images \n",
        "def img_2_block(Y, cr, max_M, max_N):\n",
        "  number_octads = int(max_M* max_N / 64)\n",
        "  Y_r = Y.reshape((number_octads, 8,8))\n",
        "  Cb_r = Cb.reshape((number_octads, 8,8))\n",
        "  Cr_r = Cr.reshape((number_octads, 8,8))\n",
        "  return Y_r, Cb_r,Cr_r\n",
        "\n",
        "\n",
        "def block_2_img(Y_r, Cb_r,Cr_r, max_M, max_N):\n",
        "  Y = Y_r.reshape((max_M, max_N)\n",
        "  Cb = Cb_r.reshape((max_M, max_N))\n",
        "  Cr = Cr_r.reshape((max_M, max_N))\n",
        "  return Y, cb, cr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUdxRgUnWwNG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}